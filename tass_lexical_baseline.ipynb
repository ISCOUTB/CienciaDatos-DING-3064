{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Instalar NLP API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T02:12:54.818293500Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:08:53.724527Z",
     "start_time": "2023-05-12T09:08:53.710532Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:08:53.738063Z",
     "start_time": "2023-05-12T09:08:53.725530Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install circlify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:08:53.799129Z",
     "start_time": "2023-05-12T09:08:53.743067Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy_syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Instalar de modelo en Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:08:53.815417Z",
     "start_time": "2023-05-12T09:08:53.756115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epuerta\\OneDrive - Universidad Tecnológica de Bolívar\\Apps\\AppsISCO\\CienciaDatos-DING-3064\\ \n",
      " C:\\Users\\epuerta\\OneDrive - Universidad Tecnológica de Bolívar\\Apps\\AppsISCO\\CienciaDatos-DING-3064\\\\logic\\ \n",
      " C:\\Users\\epuerta\\OneDrive - Universidad Tecnológica de Bolívar\\Apps\\AppsISCO\\CienciaDatos-DING-3064\\\\data\\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "PATH = os.getcwd()\n",
    "PATH = PATH + '{0}'.format(os.sep)\n",
    "LOGIC = PATH + '{0}logic{0}'.format(os.sep)\n",
    "DIR_DATA = PATH + '{0}data{0}'.format(os.sep)\n",
    "sys.path.append(PATH) if PATH not in list(sys.path) else None\n",
    "sys.path.append(DIR_DATA) if DIR_DATA not in list(sys.path) else None\n",
    "print(PATH, \"\\n\", LOGIC, \"\\n\", DIR_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:11.292094Z",
     "start_time": "2023-05-12T09:08:53.791130Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Text analysis API's\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import TweetTokenizer\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "# Preprocessin API´s\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Regularization API´s \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "\n",
    "# Feature extration API´s\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from logic.text_processing import TextProcessing\n",
    "from logic.lexical_vectorizer import LexicalVectorizer\n",
    "\n",
    "# Machine Learning Methods \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "\n",
    "# Metrics Libraries\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inicializar spaCy y cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:12.976567Z",
     "start_time": "2023-05-12T09:10:11.299027Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Importar Dataset\n",
    "\n",
    "TASS-2018: Workshop on Semantic Analysis at SEPLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:13.064429Z",
     "start_time": "2023-05-12T09:10:12.995465Z"
    }
   },
   "outputs": [],
   "source": [
    "ftrain = '{0}{1}{2}'.format(DIR_DATA, 'TASS2018', '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:13.183554Z",
     "start_time": "2023-05-12T09:10:13.033530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770976639173951488</td>\n",
       "      <td>noseashetero</td>\n",
       "      <td>@noseashetero 1000/10 de verdad a ti que voy a...</td>\n",
       "      <td>31/08/2016 13:28</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771092421866389508</td>\n",
       "      <td>Templelx</td>\n",
       "      <td>@piscolabisaereo @HistoriaNG @SPosteguillo las...</td>\n",
       "      <td>31/08/2016 21:08</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771092111429083136</td>\n",
       "      <td>esskuu94</td>\n",
       "      <td>Al final han sido 3h  Bueno, mañana tengo fies...</td>\n",
       "      <td>31/08/2016 21:07</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>771092070572449796</td>\n",
       "      <td>__ariadna9</td>\n",
       "      <td>@Jorge_Ruiz14 yo no tengo tiempo para esas cos...</td>\n",
       "      <td>31/08/2016 21:07</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>771094192508600320</td>\n",
       "      <td>_cristtina15_</td>\n",
       "      <td>@_MissChaotic_ ves ese brillo? es un coso que ...</td>\n",
       "      <td>31/08/2016 21:15</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>771116956518875137</td>\n",
       "      <td>JSorgex</td>\n",
       "      <td>Tengo una perrina adorable... Sabéis que me ac...</td>\n",
       "      <td>31/08/2016 22:46</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>771115324884262912</td>\n",
       "      <td>Escarolilla</td>\n",
       "      <td>@juankipua Es que en el Ojeando el año pasado ...</td>\n",
       "      <td>31/08/2016 22:39</td>\n",
       "      <td>es</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>771118683414560768</td>\n",
       "      <td>KaichiZick95</td>\n",
       "      <td>Bueno, estoy en la batalla final del Conquista...</td>\n",
       "      <td>31/08/2016 22:53</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>770550748107202560</td>\n",
       "      <td>carlosnmr</td>\n",
       "      <td>@CondeDuqueMAD ¿mañana sábado 31? En que día v...</td>\n",
       "      <td>30/08/2016 9:16</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>770549862500802560</td>\n",
       "      <td>hermesni</td>\n",
       "      <td>@agcasti y el caminante ante el mar de niebla,...</td>\n",
       "      <td>30/08/2016 9:12</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid           user  \\\n",
       "0  770976639173951488   noseashetero   \n",
       "1  771092421866389508       Templelx   \n",
       "2  771092111429083136       esskuu94   \n",
       "3  771092070572449796     __ariadna9   \n",
       "4  771094192508600320  _cristtina15_   \n",
       "5  771116956518875137        JSorgex   \n",
       "6  771115324884262912    Escarolilla   \n",
       "7  771118683414560768   KaichiZick95   \n",
       "8  770550748107202560      carlosnmr   \n",
       "9  770549862500802560       hermesni   \n",
       "\n",
       "                                             content              date lang  \\\n",
       "0  @noseashetero 1000/10 de verdad a ti que voy a...  31/08/2016 13:28   es   \n",
       "1  @piscolabisaereo @HistoriaNG @SPosteguillo las...  31/08/2016 21:08   es   \n",
       "2  Al final han sido 3h  Bueno, mañana tengo fies...  31/08/2016 21:07   es   \n",
       "3  @Jorge_Ruiz14 yo no tengo tiempo para esas cos...  31/08/2016 21:07   es   \n",
       "4  @_MissChaotic_ ves ese brillo? es un coso que ...  31/08/2016 21:15   es   \n",
       "5  Tengo una perrina adorable... Sabéis que me ac...  31/08/2016 22:46   es   \n",
       "6  @juankipua Es que en el Ojeando el año pasado ...  31/08/2016 22:39   es   \n",
       "7  Bueno, estoy en la batalla final del Conquista...  31/08/2016 22:53   es   \n",
       "8  @CondeDuqueMAD ¿mañana sábado 31? En que día v...   30/08/2016 9:16   es   \n",
       "9  @agcasti y el caminante ante el mar de niebla,...   30/08/2016 9:12   es   \n",
       "\n",
       "  polarity  \n",
       "0        P  \n",
       "1        P  \n",
       "2        P  \n",
       "3        N  \n",
       "4        N  \n",
       "5        P  \n",
       "6      NEU  \n",
       "7     NONE  \n",
       "8     NONE  \n",
       "9        P  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(ftrain, sep=';')\n",
    "data_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Describir Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:13.272254Z",
     "start_time": "2023-05-12T09:10:13.202201Z"
    }
   },
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Descripción del contenido "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Serie de tiempo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:16.004209Z",
     "start_time": "2023-05-12T09:10:13.282264Z"
    }
   },
   "outputs": [],
   "source": [
    "data_raw['hour'] = pd.DatetimeIndex(data_raw['date']).hour\n",
    "data_raw['minute'] = pd.DatetimeIndex(data_raw['date']).minute\n",
    "fig = px.line(data_raw, x='polarity', y='hour') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Descripción de la polaridad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:16.014117Z",
     "start_time": "2023-05-12T09:10:16.012121Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_by_polarity = data_raw.groupby(\"polarity\", as_index=False)['content'].count()\n",
    "tweet_by_polarity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:16.800189Z",
     "start_time": "2023-05-12T09:10:16.013119Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(data =tweet_by_polarity, x = \"polarity\", y = \"content\", alpha=0.8)\n",
    "plt.title('Polary Frequency by content')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 3 Uso de palabras en tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:25.839930Z",
     "start_time": "2023-05-12T09:10:16.806499Z"
    }
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "for row in tqdm(data_raw['content']):\n",
    "    doc = nlp(row.lower())\n",
    "    for token in doc:\n",
    "        if token.is_alpha and not token.is_stop:\n",
    "            if token.text in words:\n",
    "                num_temp = int(words[token.text])\n",
    "                words[token.text] = num_temp + 1\n",
    "            else:\n",
    "                words[token.text] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:25.982981Z",
     "start_time": "2023-05-12T09:10:25.844719Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_words = sorted(words.items(), key=lambda x:x[1], reverse=True)\n",
    "sorted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:26.084908Z",
     "start_time": "2023-05-12T09:10:25.977364Z"
    }
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(data = sorted_words, columns=['Word', 'Freq'])\n",
    "df_words = df_words[:20]\n",
    "df_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:26.084908Z",
     "start_time": "2023-05-12T09:10:26.023852Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_colordict(palette,number,start):\n",
    "    pal = list(sns.color_palette(palette=palette, n_colors=number).as_hex())\n",
    "    color_d = dict(enumerate(pal, start=start))\n",
    "    return color_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:26.204488Z",
     "start_time": "2023-05-12T09:10:26.043285Z"
    }
   },
   "outputs": [],
   "source": [
    "import circlify\n",
    "# compute circle positions:\n",
    "circles = circlify.circlify(df_words['Freq'][0:30].tolist(), \n",
    "                            show_enclosure=False, \n",
    "                            target_enclosure=circlify.Circle(x=0, y=0)\n",
    "                           )\n",
    "n = df_words['Freq'][0:30].max()\n",
    "color_dict = get_colordict('RdYlBu_r',n ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:26.778767Z",
     "start_time": "2023-05-12T09:10:26.135819Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,9), facecolor='white')\n",
    "ax.axis('off')\n",
    "lim = max(max(abs(circle.x)+circle.r, abs(circle.y)+circle.r,) for circle in circles)\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "\n",
    "# list of labels\n",
    "labels = list(df_words['Word'][0:40])\n",
    "counts = list(df_words['Freq'][0:40])\n",
    "labels.reverse()\n",
    "counts.reverse()\n",
    "\n",
    "# print circles\n",
    "for circle, label, count in zip(circles, labels, counts):\n",
    "    x, y, r = circle\n",
    "    ax.add_patch(plt.Circle((x, y), r, alpha=0.9, color = color_dict.get(count)))\n",
    "    plt.annotate(label +'\\n'+ str(count), (x,y), size=12, va='center', ha='center')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:33.451391Z",
     "start_time": "2023-05-12T09:10:26.785780Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_freq = {}\n",
    "for row in tqdm(data_raw['content'].to_list()):\n",
    "    doc = nlp(row.lower())\n",
    "    for token in doc:\n",
    "        if token.pos_ in pos_freq:\n",
    "            value = pos_freq[token.pos_]\n",
    "            pos_freq[token.pos_] = value + 1\n",
    "        else:\n",
    "            pos_freq[token.pos_] =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:33.516457Z",
     "start_time": "2023-05-12T09:10:33.474156Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame([[key, pos_freq[key]] for key in pos_freq.keys()], columns=['POS', 'Freq'])\n",
    "df_pos.sort_values('Freq').tail(15)\n",
    "df_pos = df_pos[:20]\n",
    "df_pos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:34.378901Z",
     "start_time": "2023-05-12T09:10:33.537564Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(data = df_pos, x = 'POS', y = 'Freq', alpha=0.8)\n",
    "plt.title('POS Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:10:34.478436Z",
     "start_time": "2023-05-12T09:10:34.399522Z"
    }
   },
   "outputs": [],
   "source": [
    "tp = TextProcessing(lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [tp.clean(row, stopwords=True) for row in data_raw['content'].tolist()]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_vector = LexicalVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lexical_vector.transform(messages)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x, index=['tweet '+str(i) for i in range(1, 1+len(messages))])\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_raw['polarity']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "xx_train, yy_train = oversample.fit_resample(x_train, y_train)\n",
    "xx_test, yy_test = oversample.fit_resample(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "Counter(yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = ShuffleSplit(n_splits=10, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"DT\", DecisionTreeClassifier(max_depth=70, min_samples_leaf=1, min_samples_split=3)),\n",
    "          (\"SVM\", SVC(kernel='linear', C=0.5, probability=True)),\n",
    "          (\"RF\", RandomForestClassifier(n_estimators=200, max_depth=6, random_state=0)),\n",
    "          (\"NB\", GaussianNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResults = []\n",
    "cmList = []\n",
    "for name, model in models:\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for train_index, test_index in k_fold.split(xx_train, yy_train):\n",
    "        data_train = xx_train[train_index]\n",
    "        target_train = yy_train[train_index]\n",
    "\n",
    "        data_test = xx_train[test_index]\n",
    "        target_test = yy_train[test_index]\n",
    "\n",
    "        model.fit(data_train, target_train)\n",
    "        predict = model.predict(data_test)\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(target_test, predict, normalize=True)\n",
    "        accuracies.append(accuracy)\n",
    "        # Precision\n",
    "        precision = precision_score(target_test, predict, average=\"macro\")\n",
    "        precisions.append(precision)\n",
    "        # recall\n",
    "        recall = recall_score(target_test, predict, average=\"macro\")\n",
    "        recalls.append(recall)\n",
    "        # f1\n",
    "        f1 = f1_score(target_test, predict, average=\"macro\")\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    y_test_predict = model.predict(xx_test)\n",
    "    cm= confusion_matrix(yy_test, y_test_predict)\n",
    "    \n",
    "    finalResults.append({'name':name, \n",
    "                         'model': model,\n",
    "                         'accuracy': round(np.mean(accuracies), 2), \n",
    "                         'precision': round(np.mean(precisions), 2),\n",
    "                         'recall': round(np.mean(recalls), 2),\n",
    "                         'f1': round(np.mean(f1s), 2),\n",
    "                         'confusion_matrix': cm\n",
    "                        })\n",
    "    cmList.append((name,cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame.from_dict(finalResults)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name , i in cmList:\n",
    "    plt.figure()\n",
    "    sns.heatmap(i , annot =True, linewidth=0.8,fmt=\".1f\")\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
